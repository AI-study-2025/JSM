## AAE: [Adversarial Auto Encoder](https://arxiv.org/abs/1511.05644) <br>
간단 정리 : AutoEncoder의 구조와 Advarsarial 학습을 사용하여 두가지의 장점을 모두 살린 생성형 모델입니다.

## DETR: [https://arxiv.org/abs/2005.12872](https://arxiv.org/abs/2005.12872)  <br>
간단 정리 : 객체 탐지의 복잡한 파이프라인을 사용하는 대신 집합 에측이라는 새로운 관점과 트랜스포머 아키텍처를 사용한 간단한 파이프라인을 제안하였습니다. <br>
[BLOG](https://velog.io/@seungminchung/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-DETR)

## Co-DETR: [https://arxiv.org/abs/2211.12860](https://arxiv.org/abs/2211.12860)  <br>
간단 정리 : DETR에서 양성 쿼리의 수가 적어 효율적인 학습을 할수 없음을 지적하며, 보조 헤드를 통해 인위적으로 양성 쿼리를 만듦으로써 보다 효율적으로 학습하는 방법을 제안하였습니다. <br>
[BLOG](https://velog.io/@seungminchung/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-Co-DETR-DETR-with-Collaborative-Hybrid-Assignments-Training)

## Swin-Transformer: [https://arxiv.org/abs/2103.14030](https://arxiv.org/abs/2103.14030) <br>
간단 정리 : 기존의 ViT에서는 고정된 크기의 이미지, 해상도에 따른 연산량 2차식 증가 문제 제기, 계층적 구조, window와 shifted window 기반의 self-multi-head attention 제안으로 vision task의 백본을 제안  <br>
[BLOG](https://velog.io/@seungminchung/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows)


## Segment Anything: [https://arxiv.org/abs/2304.02643](https://arxiv.org/abs/2304.02643) <br>
간단 정리 : segmentation 분야에서 Foundation 모델을 제안하였습니다. Promptable 모델을 활용, 데이터를 얻기 위한 data engine 등을 활용하여 어떠한 Prompt에 대해서도 segment를 진행하는 모델과 데이터를 제안하였습니다.  <br>
[BLOG](https://velog.io/@seungminchung/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-SA-segment-Anythings)

## End to End Learning for Self-Driving Cars : [https://arxiv.org/abs/1604.07316](https://arxiv.org/abs/1604.07316) <br>
간단 정리 : CNN의 특징 추출과 운전대의 각도 데이터만을 활용하여 End-to-End 방식으로 자율주행이 가능함을 입증하였습니다.  <br>
[BLOG](https://velog.io/@seungminchung/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-End-to-End-Learning-for-Self-Driving-cars)
